name: Phase 1 CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  BUILD_TYPE: Release

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    
    services:
      questdb:
        image: questdb/questdb:8.0.0
        ports:
          - 9000:9000
          - 8812:8812
          - 9009:9009
        options: >-
          --health-cmd "curl -f http://localhost:9000/status || exit 1"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 5
          --health-start-period 30s
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          clang-15 \
          cmake \
          ninja-build \
          python3 \
          python3-pip \
          curl \
          docker-compose
        
        # Install Python dependencies
        pip3 install numpy
        
        # Set clang as default compiler
        sudo update-alternatives --install /usr/bin/clang clang /usr/bin/clang-15 100
        sudo update-alternatives --install /usr/bin/clang++ clang++ /usr/bin/clang++-15 100
    
    - name: Verify environment
      run: |
        clang++ --version
        cmake --version
        python3 --version
        docker --version
        docker-compose --version
    
    - name: Configure CMake
      run: |
        cmake -B build \
          -DCMAKE_BUILD_TYPE=${{env.BUILD_TYPE}} \
          -DCMAKE_CXX_COMPILER=clang++ \
          -G Ninja
    
    - name: Build project
      run: cmake --build build --config ${{env.BUILD_TYPE}} --parallel
    
    - name: Run unit tests
      run: |
        cd build
        ctest --output-on-failure --parallel 2
    
    - name: Run performance tests
      run: |
        cd build
        ./tests/perf_harness --validate-slo --num-ticks 5000
    
    - name: Check code format
      run: |
        find src -name "*.cpp" -o -name "*.h" | xargs clang-format-15 --dry-run --Werror
    
    - name: Generate test data
      run: |
        mkdir -p test_data
        python3 scripts/hawkes_gen.py \
          --duration 60 \
          --scenario normal_trading \
          --seed 42 \
          test_data/ci_test_ticks.csv
    
    - name: Test ingest (replay mode)
      run: |
        cd build
        timeout 120 ./src/engine/ingest/ingest_app replay ../test_data/ci_test_ticks.csv || true
    
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: build-artifacts
        path: |
          build/
          test_data/
          unit_perf_report.json
          perf_report.json
        retention-days: 7

  performance-regression-check:
    runs-on: ubuntu-latest
    needs: build-and-test
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for comparison
    
    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-artifacts
    
    - name: Check performance regression
      run: |
        # This is a placeholder for Phase 1
        # In Phase 2, we'll implement proper regression detection
        
        echo "Checking for performance regressions..."
        
        if [ -f "unit_perf_report.json" ]; then
          echo "Performance report found"
          cat unit_perf_report.json
          
          # Simple check: fail if SLO not met
          if ! python3 -c "
import json
with open('unit_perf_report.json') as f:
    data = json.load(f)
    exit(0 if data.get('slo_passed', False) else 1)
"; then
            echo "‚ùå Performance regression detected: SLO not met"
            exit 1
          fi
          
          echo "‚úÖ No performance regression detected"
        else
          echo "‚ö†Ô∏è  No performance report found"
        fi

  security-scan:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Run static analysis
      run: |
        sudo apt-get update
        sudo apt-get install -y clang-tidy-15
        
        # Run clang-tidy on source files
        find src -name "*.cpp" | head -5 | xargs clang-tidy-15 \
          --checks="-*,clang-analyzer-*,bugprone-*,performance-*" \
          --warnings-as-errors="*" || true
    
    - name: Check for hardcoded secrets
      run: |
        # Basic secret scanning
        if grep -r "password\|secret\|key\|token" src/ --include="*.cpp" --include="*.h" | grep -v "TODO"; then
          echo "‚ùå Potential hardcoded secrets found"
          exit 1
        fi
        echo "‚úÖ No obvious secrets found"

  docker-integration:
    runs-on: ubuntu-latest
    needs: build-and-test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Start QuestDB
      run: |
        docker-compose up -d questdb
        
        # Wait for QuestDB to be ready
        timeout 60 bash -c 'until curl -f http://localhost:9000/status; do sleep 2; done'
    
    - name: Verify QuestDB schema
      run: |
        # Test that we can connect and query QuestDB
        curl -G "http://localhost:9000/exec" \
          --data-urlencode "query=SELECT 1" | jq .
    
    - name: Test metrics endpoint simulation
      run: |
        # Test that we can start a simple metrics server
        python3 -c "
import http.server
import socketserver
import threading
import time

class MetricsHandler(http.server.SimpleHTTPRequestHandler):
    def do_GET(self):
        if self.path == '/metrics':
            self.send_response(200)
            self.send_header('Content-type', 'text/plain')
            self.end_headers()
            self.wfile.write(b'# Test metrics\ntest_metric 1\n')
        else:
            self.send_response(404)
            self.end_headers()

with socketserver.TCPServer(('', 8080), MetricsHandler) as httpd:
    server_thread = threading.Thread(target=httpd.serve_forever, daemon=True)
    server_thread.start()
    time.sleep(1)
    
    import urllib.request
    response = urllib.request.urlopen('http://localhost:8080/metrics')
    print('Metrics endpoint test:', response.read().decode())
    httpd.shutdown()
"
    
    - name: Cleanup
      if: always()
      run: |
        docker-compose down --timeout 10

  phase1-validation:
    runs-on: ubuntu-latest
    needs: [build-and-test, performance-regression-check, security-scan, docker-integration]
    if: always()
    
    steps:
    - name: Validate Phase 1 completion
      run: |
        echo "Phase 1 Validation Results:"
        echo "=========================="
        
        # Check if all jobs passed
        if [ "${{ needs.build-and-test.result }}" = "success" ] && \
           [ "${{ needs.security-scan.result }}" = "success" ] && \
           [ "${{ needs.docker-integration.result }}" = "success" ]; then
          echo "‚úÖ All Phase 1 requirements met"
          echo "üìä Build and test: ${{ needs.build-and-test.result }}"
          echo "üîí Security scan: ${{ needs.security-scan.result }}"
          echo "üê≥ Docker integration: ${{ needs.docker-integration.result }}"
          
          # Performance regression check is only for PRs
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "‚ö° Performance check: ${{ needs.performance-regression-check.result }}"
          fi
          
          exit 0
        else
          echo "‚ùå Phase 1 validation failed"
          echo "üìä Build and test: ${{ needs.build-and-test.result }}"
          echo "üîí Security scan: ${{ needs.security-scan.result }}"
          echo "üê≥ Docker integration: ${{ needs.docker-integration.result }}"
          
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "‚ö° Performance check: ${{ needs.performance-regression-check.result }}"
          fi
          
          exit 1
        fi